{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA_4: Feedforward Neural Network\n",
    "\n",
    "## Aim\n",
    "Train and test a Feedforward Neural Network for MNIST digit classification.\n",
    "\n",
    "## Procedure\n",
    "* Download `mnist_file.rar` which contains mnist data as a *pickle* file and read `mnist.py` for loading partial mnist data.\n",
    "* Run read `mnist.py` file which will give 1000 train and 500 test images per each class.\n",
    "* x train,y train gives the image $784\\times1$ and corresponding label for training data. Similarly, for test data.\n",
    "* Write\n",
    "1. Neural network model using library functions.\n",
    "2. Your own neural network model and train with Back propagation\n",
    "    1. On the training data and report accuracy.\n",
    "    2. Train with Five fold cross validation (4 fold training and 1 fold testing. Repeating this for 5 times changing the test fold each time) and report the average accuracy as train accuracy.\n",
    "* Test both models with the test data.\n",
    "* Find the confusion matrix and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import visualise\n",
    "from read_mnist import load_data\n",
    "import random\n",
    "\n",
    "y_train,x_train,y_test,x_test=load_data()\n",
    "\n",
    "print(\"Train data label dim: {}\".format(y_train.shape))\n",
    "print(\"Train data features dim: {}\".format(x_train.shape))\n",
    "print(\"Test data label dim: {}\".format(y_test.shape))\n",
    "print(\"Test data features dim:{}\".format(x_test.shape))\n",
    "\n",
    "visualise(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return sigmoid(x) * ( 1 - sigmoid(x) )\n",
    "\n",
    "# def tanh():\n",
    "\n",
    "\n",
    "# def ReLU():\n",
    "        \n",
    "class NN:\n",
    "    def __init__(self, num_layers, depth, act):\n",
    "        self.num_layers = num_layers\n",
    "        self.depth = depth\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self,x_train):\n",
    "        w = np.random.randn(x_train.shape[1], self.depth) * 0.01\n",
    "        b = np.random.randn(1, self.depth) * 0.01\n",
    "        print(w.shape)\n",
    "        print(b.shape)\n",
    "        score = np.dot(x_train, w) + b\n",
    "        print(score.shape)\n",
    "        \n",
    "    def backward(self):\n",
    "        pass\n",
    "\n",
    "# def preprocess(X):\n",
    "#     # zero center the data\n",
    "#     X -= np.mean(X, axis = 0)\n",
    "#     return X\n",
    "\n",
    "# preprocessing the image\n",
    "# x_train=preprocess(x_train)\n",
    "# x_test=preprocess(x_test)\n",
    "\n",
    "model = NN(num_layers=5,depth=256,act=\"sigmoid\")\n",
    "model.forward(x_train)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data label dim: (10000,)\n",
      "Train data features dim: (10000, 784)\n",
      "Test data label dim: (5000,)\n",
      "Test data features dim:(5000, 784)\n",
      "Loss: 11.518933256651728 in 0/10\n",
      "dW1: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] dW2: [[-0.04838838 -0.04963675 -0.04760876 ... -0.04764656 -0.04817444\n",
      "  -0.0483646 ]\n",
      " [-0.05114034 -0.04875452 -0.04969969 ... -0.04938899 -0.05008567\n",
      "  -0.05016968]\n",
      " [-0.05180031 -0.05161987 -0.05204767 ... -0.05119931 -0.05121662\n",
      "  -0.05113887]\n",
      " ...\n",
      " [-0.05063255 -0.0515161  -0.05053076 ... -0.04944979 -0.05002934\n",
      "  -0.04915459]\n",
      " [-0.05289349 -0.05041991 -0.05018145 ... -0.05005996 -0.05023035\n",
      "  -0.05026941]\n",
      " [-0.05653962 -0.04941076 -0.05315421 ... -0.05230298 -0.0524291\n",
      "  -0.0529183 ]]\n",
      "Loss: 11.536884406029197 in 1/10\n",
      "dW1: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] dW2: [[-0.09999256 -0.0999901  -0.099987   ... -0.09995615 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.0999925  -0.0999901  -0.099987   ... -0.09995771 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999239 -0.0999901  -0.099987   ... -0.09995222 -0.09999013\n",
      "  -0.09998613]\n",
      " ...\n",
      " [-0.09999254 -0.0999901  -0.099987   ... -0.09995569 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999247 -0.0999901  -0.099987   ... -0.09995579 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999238 -0.0999901  -0.099987   ... -0.09995725 -0.09999013\n",
      "  -0.09998613]]\n",
      "Loss: 11.536889719920445 in 2/10\n",
      "dW1: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] dW2: [[-0.09999257 -0.0999901  -0.099987   ... -0.09995642 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999251 -0.0999901  -0.099987   ... -0.09995797 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.0999924  -0.0999901  -0.099987   ... -0.09995256 -0.09999013\n",
      "  -0.09998613]\n",
      " ...\n",
      " [-0.09999255 -0.0999901  -0.099987   ... -0.09995598 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999248 -0.0999901  -0.099987   ... -0.09995607 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999239 -0.0999901  -0.099987   ... -0.09995753 -0.09999013\n",
      "  -0.09998613]]\n",
      "Loss: 11.536896441885903 in 3/10\n",
      "dW1: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] dW2: [[-0.09999258 -0.0999901  -0.099987   ... -0.09995722 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999253 -0.0999901  -0.099987   ... -0.09995873 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999242 -0.0999901  -0.099987   ... -0.09995354 -0.09999013\n",
      "  -0.09998613]\n",
      " ...\n",
      " [-0.09999257 -0.0999901  -0.099987   ... -0.0999568  -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.0999925  -0.0999901  -0.099987   ... -0.09995689 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999241 -0.0999901  -0.099987   ... -0.09995832 -0.09999013\n",
      "  -0.09998613]]\n",
      "Loss: 11.53690394950849 in 4/10\n",
      "dW1: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] dW2: [[-0.09999261 -0.0999901  -0.099987   ... -0.09995849 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999256 -0.0999901  -0.099987   ... -0.09995993 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999246 -0.0999901  -0.099987   ... -0.09995508 -0.09999013\n",
      "  -0.09998613]\n",
      " ...\n",
      " [-0.09999259 -0.0999901  -0.099987   ... -0.09995812 -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999253 -0.0999901  -0.099987   ... -0.0999582  -0.09999013\n",
      "  -0.09998613]\n",
      " [-0.09999244 -0.0999901  -0.099987   ... -0.09995957 -0.09999013\n",
      "  -0.09998613]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1897fb211653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: {} in {}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1897fb211653>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_train)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0ms1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1897fb211653>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import visualise\n",
    "from read_mnist import load_data\n",
    "import random\n",
    "\n",
    "y_train,x_train,y_test,x_test=load_data()\n",
    "print(\"Train data label dim: {}\".format(y_train.shape))\n",
    "print(\"Train data features dim: {}\".format(x_train.shape))\n",
    "print(\"Test data label dim: {}\".format(y_test.shape))\n",
    "print(\"Test data features dim:{}\".format(x_test.shape))\n",
    "\n",
    "# uncomment to visualise dataset\n",
    "# visualise(x_train)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return sigmoid(x).T @ (1 - sigmoid(x))\n",
    "\n",
    "# def softmax(x):\n",
    "#     for i,f in enumerate(x):\n",
    "#         f -= np.max(f) # for numerical stabiluty\n",
    "#         p = np.exp(f) / np.sum(np.exp(f))\n",
    "#         x[i,:]=p\n",
    "#     return x\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def cross_entropy(y_,y):\n",
    "    n = y.shape[0]\n",
    "    nll = -np.log(y_[range(n),y])\n",
    "    return np.mean(nll)\n",
    "\n",
    "def delta_cross_entropy(y_,y):\n",
    "    n = y.shape[0]\n",
    "    y_[range(n),y] -= 1\n",
    "    return y_/n\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, hidden_layers, hidden_neurons, hidden_activation):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.step_size=0.01\n",
    "\n",
    "        self.W1 = 0.01* np.random.randn(x_train.shape[1],self.hidden_neurons)\n",
    "        self.b1 = np.zeros((1,self.hidden_neurons))\n",
    "        self.W2 = 0.01* np.random.randn(self.hidden_neurons,10)\n",
    "        self.b2 = np.zeros((1,10))\n",
    "\n",
    "    def forward(self,x_train):\n",
    "        s1=np.dot(x_train, self.W1)\n",
    "        a1 = (sigmoid(s1))\n",
    "        s2 = np.dot(a1, self.W2)\n",
    "        a2 = softmax(s2)\n",
    "        loss=cross_entropy(a2,y_train)\n",
    "        return(loss,s1,a1,s2,a2)\n",
    "\n",
    "\n",
    "    def backward(self, s1, a1, s2, a2):\n",
    "        ds2=delta_cross_entropy(a2,y_train)\n",
    "        dW2 = np.dot(a1.T, ds2)\n",
    "#         db2 = np.sum(ds2, axis=0)\n",
    "#         self.b2 += -self.step_size * db2\n",
    "        dW1 = np.dot(x_train.T, np.dot(np.dot(ds2,self.W2.T),sigmoid_grad(s1)))\n",
    "#         db1 = np.sum(np.dot(np.dot(ds2,self.W2.T),sigmoid_grad(s1)),axis=0)\n",
    "#         db1.reshape(1,-1)\n",
    "\n",
    "        self.W1 += -self.step_size * dW1\n",
    "        self.W2 += -self.step_size * dW2\n",
    "\n",
    "#         self.b1 += -self.step_size * db1\n",
    "        print(\"dW1:\", dW1, \"dW2:\", dW2)\n",
    "\n",
    "model=NN(5,512,\"sigmoid\")\n",
    "epochs=10\n",
    "for epoch in range(epochs):\n",
    "    loss,s1,a1,s2,a2 = model.forward(x_train)\n",
    "    print(\"Loss: {} in {}/{}\".format(loss,epoch,epochs))\n",
    "    model.backward(s1, a1, s2, a2)\n",
    "\n",
    "print(a2.shape)\n",
    "preds= np.argmax(a2, axis=1)\n",
    "print(preds.shape, y_train.shape)\n",
    "print('training accuracy: {}'.format(np.mean(preds == y_train)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
