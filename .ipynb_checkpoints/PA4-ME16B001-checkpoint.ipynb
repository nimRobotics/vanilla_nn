{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA_4: Feedforward Neural Network\n",
    "\n",
    "## Aim\n",
    "Train and test a Feedforward Neural Network for MNIST digit classification.\n",
    "\n",
    "## Procedure\n",
    "* Download `mnist_file.rar` which contains mnist data as a *pickle* file and read `mnist.py` for loading partial mnist data.\n",
    "* Run read `mnist.py` file which will give 1000 train and 500 test images per each class.\n",
    "* x train,y train gives the image $784\\times1$ and corresponding label for training data. Similarly, for test data.\n",
    "* Write\n",
    "1. Neural network model using library functions.\n",
    "2. Your own neural network model and train with Back propagation\n",
    "    1. On the training data and report accuracy.\n",
    "    2. Train with Five fold cross validation (4 fold training and 1 fold testing. Repeating this for 5 times changing the test fold each time) and report the average accuracy as train accuracy.\n",
    "* Test both models with the test data.\n",
    "* Find the confusion matrix and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data label dim: (10000,)\n",
      "Train data features dim: (10000, 784)\n",
      "Test data label dim: (5000,)\n",
      "Test data features dim:(5000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import visualise\n",
    "from read_mnist import load_data\n",
    "import random\n",
    "\n",
    "y_train,x_train,y_test,x_test=load_data()\n",
    "\n",
    "print(\"Train data label dim: {}\".format(y_train.shape))\n",
    "print(\"Train data features dim: {}\".format(x_train.shape))\n",
    "print(\"Test data label dim: {}\".format(y_test.shape))\n",
    "print(\"Test data features dim:{}\".format(x_test.shape))\n",
    "\n",
    "visualise(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############ Activation function: sigmoid No. of neurons: 32 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.2976980059250627 Training progress: 0/1000\n",
      "Loss: 1.8916338328561102 Training progress: 100/1000\n",
      "Loss: 1.3950471903399146 Training progress: 200/1000\n",
      "Loss: 1.0668814656330095 Training progress: 300/1000\n",
      "Loss: 0.868261085654091 Training progress: 400/1000\n",
      "Loss: 0.7362683356730162 Training progress: 500/1000\n",
      "Loss: 0.6426551204596254 Training progress: 600/1000\n",
      "Loss: 0.5737353705152737 Training progress: 700/1000\n",
      "Loss: 0.5216783262541892 Training progress: 800/1000\n",
      "Loss: 0.48145599108204695 Training progress: 900/1000\n",
      "Training finished in 133.13766050338745 s\n",
      "Test Results-Accuracy: 0.8944 F1-Score: 0.8944, Precision: 0.8944 Recall: 0.8944\n",
      "\n",
      "############ Activation function: relu No. of neurons: 32 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.269555119614911 Training progress: 0/1000\n",
      "Loss: 0.6242387675986449 Training progress: 100/1000\n",
      "Loss: 0.4284764079208213 Training progress: 200/1000\n",
      "Loss: 0.36111171017770066 Training progress: 300/1000\n",
      "Loss: 0.32309172002313197 Training progress: 400/1000\n",
      "Loss: 0.29654220850059526 Training progress: 500/1000\n",
      "Loss: 0.2762474864083992 Training progress: 600/1000\n",
      "Loss: 0.25974846950766367 Training progress: 700/1000\n",
      "Loss: 0.2457748162581262 Training progress: 800/1000\n",
      "Loss: 0.23347880442289415 Training progress: 900/1000\n",
      "Training finished in 116.51179671287537 s\n",
      "Test Results-Accuracy: 0.3912 F1-Score: 0.3912, Precision: 0.3912 Recall: 0.3912\n",
      "\n",
      "############ Activation function: tanh No. of neurons: 32 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.297815714039517 Training progress: 0/1000\n",
      "Loss: 0.8037935708595644 Training progress: 100/1000\n",
      "Loss: 0.5207022882099225 Training progress: 200/1000\n",
      "Loss: 0.4158580124491642 Training progress: 300/1000\n",
      "Loss: 0.36120526288908106 Training progress: 400/1000\n",
      "Loss: 0.3264878670926226 Training progress: 500/1000\n",
      "Loss: 0.3016128198438327 Training progress: 600/1000\n",
      "Loss: 0.28234511365221726 Training progress: 700/1000\n",
      "Loss: 0.2666073131446428 Training progress: 800/1000\n",
      "Loss: 0.25325584886187846 Training progress: 900/1000\n",
      "Training finished in 145.9123134613037 s\n",
      "Test Results-Accuracy: 0.7106 F1-Score: 0.7106, Precision: 0.7106 Recall: 0.7106\n",
      "\n",
      "############ Activation function: sigmoid No. of neurons: 64 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.3728836095253456 Training progress: 0/1000\n",
      "Loss: 1.7241328151776205 Training progress: 100/1000\n",
      "Loss: 1.1472550756147943 Training progress: 200/1000\n",
      "Loss: 0.8463646262086623 Training progress: 300/1000\n",
      "Loss: 0.6881023106662657 Training progress: 400/1000\n",
      "Loss: 0.5924568914008324 Training progress: 500/1000\n",
      "Loss: 0.5281937604976743 Training progress: 600/1000\n",
      "Loss: 0.48190210622083485 Training progress: 700/1000\n",
      "Loss: 0.4469802809664857 Training progress: 800/1000\n",
      "Loss: 0.41972671753562973 Training progress: 900/1000\n",
      "Training finished in 170.92151355743408 s\n",
      "Test Results-Accuracy: 0.8998 F1-Score: 0.8998, Precision: 0.8998 Recall: 0.8998\n",
      "\n",
      "############ Activation function: relu No. of neurons: 64 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.46205134900947 Training progress: 0/1000\n",
      "Loss: 0.5452346160961845 Training progress: 100/1000\n",
      "Loss: 0.3919195300588397 Training progress: 200/1000\n",
      "Loss: 0.33410957570720823 Training progress: 300/1000\n",
      "Loss: 0.29983103214720325 Training progress: 400/1000\n",
      "Loss: 0.27539430852837027 Training progress: 500/1000\n",
      "Loss: 0.25608516942196546 Training progress: 600/1000\n",
      "Loss: 0.23979069843354883 Training progress: 700/1000\n",
      "Loss: 0.2255801369370733 Training progress: 800/1000\n",
      "Loss: 0.2129880420400791 Training progress: 900/1000\n",
      "Training finished in 152.53190231323242 s\n",
      "Test Results-Accuracy: 0.6416 F1-Score: 0.6416, Precision: 0.6416 Recall: 0.6416\n",
      "\n",
      "############ Activation function: tanh No. of neurons: 64 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.486235461068752 Training progress: 0/1000\n",
      "Loss: 0.6411966675892914 Training progress: 100/1000\n",
      "Loss: 0.44876333132110613 Training progress: 200/1000\n",
      "Loss: 0.3743077580021445 Training progress: 300/1000\n",
      "Loss: 0.3321754601490864 Training progress: 400/1000\n",
      "Loss: 0.30329164891329224 Training progress: 500/1000\n",
      "Loss: 0.2812130317262196 Training progress: 600/1000\n",
      "Loss: 0.2632125909493916 Training progress: 700/1000\n",
      "Loss: 0.24793190980962904 Training progress: 800/1000\n",
      "Loss: 0.23460048669570696 Training progress: 900/1000\n",
      "Training finished in 205.7029266357422 s\n",
      "Test Results-Accuracy: 0.744 F1-Score: 0.744, Precision: 0.744 Recall: 0.744\n",
      "\n",
      "############ Activation function: sigmoid No. of neurons: 128 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.4511414536847203 Training progress: 0/1000\n",
      "Loss: 1.361768291059137 Training progress: 100/1000\n",
      "Loss: 0.8774462245443572 Training progress: 200/1000\n",
      "Loss: 0.6707298021246534 Training progress: 300/1000\n",
      "Loss: 0.5630151532967453 Training progress: 400/1000\n",
      "Loss: 0.49749088463945557 Training progress: 500/1000\n",
      "Loss: 0.4534288846861791 Training progress: 600/1000\n",
      "Loss: 0.4216509844482158 Training progress: 700/1000\n",
      "Loss: 0.3975045596057303 Training progress: 800/1000\n",
      "Loss: 0.3784004123617001 Training progress: 900/1000\n",
      "Training finished in 255.1411576271057 s\n",
      "Test Results-Accuracy: 0.9032 F1-Score: 0.9032, Precision: 0.9032 Recall: 0.9032\n",
      "\n",
      "############ Activation function: relu No. of neurons: 128 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.527643352946005 Training progress: 0/1000\n",
      "Loss: 0.4811591611774168 Training progress: 100/1000\n",
      "Loss: 0.3563388145136616 Training progress: 200/1000\n",
      "Loss: 0.3047357695189314 Training progress: 300/1000\n",
      "Loss: 0.2728644834221996 Training progress: 400/1000\n",
      "Loss: 0.24941941462432568 Training progress: 500/1000\n",
      "Loss: 0.2305772591318516 Training progress: 600/1000\n",
      "Loss: 0.21463090129702933 Training progress: 700/1000\n",
      "Loss: 0.20071292077836766 Training progress: 800/1000\n",
      "Loss: 0.18829770482092198 Training progress: 900/1000\n",
      "Training finished in 207.65033602714539 s\n",
      "Test Results-Accuracy: 0.6182 F1-Score: 0.6182, Precision: 0.6182 Recall: 0.6182\n",
      "\n",
      "############ Activation function: tanh No. of neurons: 128 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.5389343639703488 Training progress: 0/1000\n",
      "Loss: 0.5131984031814634 Training progress: 100/1000\n",
      "Loss: 0.3843348136605855 Training progress: 200/1000\n",
      "Loss: 0.3305415509229115 Training progress: 300/1000\n",
      "Loss: 0.2978394412661658 Training progress: 400/1000\n",
      "Loss: 0.2742960989036736 Training progress: 500/1000\n",
      "Loss: 0.25569848367763487 Training progress: 600/1000\n",
      "Loss: 0.24016188117894777 Training progress: 700/1000\n",
      "Loss: 0.22670973696790178 Training progress: 800/1000\n",
      "Loss: 0.2147817443362571 Training progress: 900/1000\n",
      "Training finished in 298.36730337142944 s\n",
      "Test Results-Accuracy: 0.6978 F1-Score: 0.6978, Precision: 0.6978 Recall: 0.6978\n",
      "\n",
      "############ Activation function: sigmoid No. of neurons: 256 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.580564538930428 Training progress: 0/1000\n",
      "Loss: 1.0138689173390734 Training progress: 100/1000\n",
      "Loss: 0.6771119856265364 Training progress: 200/1000\n",
      "Loss: 0.5470936515953743 Training progress: 300/1000\n",
      "Loss: 0.4781541085766841 Training progress: 400/1000\n",
      "Loss: 0.43488129997762437 Training progress: 500/1000\n",
      "Loss: 0.40480394726231006 Training progress: 600/1000\n",
      "Loss: 0.38241894853662195 Training progress: 700/1000\n",
      "Loss: 0.36492145921891295 Training progress: 800/1000\n",
      "Loss: 0.3507311061424783 Training progress: 900/1000\n",
      "Training finished in 371.72948837280273 s\n",
      "Test Results-Accuracy: 0.9162 F1-Score: 0.9162, Precision: 0.9162 Recall: 0.9162\n",
      "\n",
      "############ Activation function: relu No. of neurons: 256 ############\n",
      "\n",
      "Training started!\n",
      "Loss: 2.722196586738837 Training progress: 0/1000\n",
      "Loss: 0.404859005347794 Training progress: 100/1000\n",
      "Loss: 0.31175495813611853 Training progress: 200/1000\n",
      "Loss: 0.26796096085328386 Training progress: 300/1000\n",
      "Loss: 0.2390212001439132 Training progress: 400/1000\n",
      "Loss: 0.21704757548543116 Training progress: 500/1000\n",
      "Loss: 0.19926481444159858 Training progress: 600/1000\n",
      "Loss: 0.18421822585025985 Training progress: 700/1000\n",
      "Loss: 0.17110958597477263 Training progress: 800/1000\n",
      "Loss: 0.1595461440742739 Training progress: 900/1000\n",
      "Training finished in 288.74966502189636 s\n",
      "Test Results-Accuracy: 0.3168 F1-Score: 0.3168, Precision: 0.3168 Recall: 0.3168\n",
      "\n",
      "############ Activation function: tanh No. of neurons: 256 ############\n",
      "\n",
      "Training started!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.80472378970434 Training progress: 0/1000\n",
      "Loss: 0.42582469462082784 Training progress: 100/1000\n",
      "Loss: 0.3369965408855408 Training progress: 200/1000\n",
      "Loss: 0.295382842483104 Training progress: 300/1000\n",
      "Loss: 0.2681059751763126 Training progress: 400/1000\n",
      "Loss: 0.24749224386351362 Training progress: 500/1000\n",
      "Loss: 0.23069665713292806 Training progress: 600/1000\n",
      "Loss: 0.21638732353685305 Training progress: 700/1000\n",
      "Loss: 0.2038410978627454 Training progress: 800/1000\n",
      "Loss: 0.19262277824548682 Training progress: 900/1000\n",
      "Training finished in 448.80676102638245 s\n",
      "Test Results-Accuracy: 0.5506 F1-Score: 0.5506, Precision: 0.5506 Recall: 0.5506\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from read_mnist import load_data\n",
    "import pickle\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def tanh_grad(x):\n",
    "    return 1-np.power(x,2)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x /np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def relu_grad(x):\n",
    "    return (x>0)*1\n",
    "\n",
    "def cross_entropy(y_,y):\n",
    "    n = y.shape[0]\n",
    "    nll = -np.log(y_[range(n),y])\n",
    "    return np.mean(nll)\n",
    "\n",
    "def delta_cross_entropy(y_,y):\n",
    "    n = y.shape[0]\n",
    "    y_[range(n),y] -= 1\n",
    "    return y_/n\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, hidden_layers, hidden_neurons, hidden_activation, lr=0.01):\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.hidden_activation = hidden_activation\n",
    "        self.lr=lr\n",
    "        np.random.seed(786)\n",
    "        self.W1 = 0.1* np.random.randn(x_train.shape[1],self.hidden_neurons)\n",
    "        self.b1 = np.zeros((1,self.hidden_neurons))\n",
    "        self.W2 = 0.1* np.random.randn(self.hidden_neurons,10)\n",
    "        self.b2 = np.zeros((1,10))\n",
    "\n",
    "    def forward(self,x_train):\n",
    "        s1=np.dot(x_train, self.W1) + self.b1\n",
    "        if self.hidden_activation == 'sigmoid':\n",
    "            a1 = sigmoid(s1)\n",
    "        elif self.hidden_activation=='tanh':\n",
    "            a1 = np.tanh(s1)\n",
    "        elif self.hidden_activation=='relu':\n",
    "            a1 = relu(s1)\n",
    "        else:\n",
    "            raise Exception('Error: Activation not implemented')\n",
    "        s2 = np.dot(a1, self.W2) + self.b2\n",
    "        a2 = softmax(s2)\n",
    "        loss=cross_entropy(a2,y_train)\n",
    "        return(loss,s1,a1,s2,a2)\n",
    "\n",
    "\n",
    "    def backward(self, s1, a1, s2, a2):\n",
    "        delta3=delta_cross_entropy(a2,y_train)\n",
    "        dW2 = np.dot(a1.T, delta3)\n",
    "        db2 = np.sum(delta3, axis=0, keepdims=True)\n",
    "        if self.hidden_activation=='sigmoid':\n",
    "            delta2 = delta3.dot(self.W2.T) * sigmoid_grad(a1)\n",
    "        elif self.hidden_activation == 'tanh':\n",
    "            delta2 = delta3.dot(self.W2.T) * tanh_grad(a1)\n",
    "        elif self.hidden_activation == 'relu':\n",
    "            delta2 = delta3.dot(self.W2.T) * relu_grad(a1)\n",
    "        else:\n",
    "            raise Exception('Error: Activation not implemented')\n",
    "            \n",
    "        dW1 = np.dot(x_train.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    "\n",
    "        self.W1 += -self.lr * dW1\n",
    "        self.b1 += -self.lr * db1\n",
    "        self.W2 += -self.lr * dW2\n",
    "        self.b2 += -self.lr * db2\n",
    "        \n",
    "    def predict(self, x):\n",
    "        s1=np.dot(x, self.W1)\n",
    "        a1 = (sigmoid(s1))\n",
    "        s2 = np.dot(a1, self.W2)\n",
    "        a2 = softmax(s2)\n",
    "        return np.argmax(a2, axis=1)\n",
    "    \n",
    "    def save_model(self, name):\n",
    "        params = { 'W1': self.W1, 'b1': self.b1, 'W2': self.W2, 'b2': self.b2}\n",
    "        with open(name, 'wb') as handle:\n",
    "            pickle.dump(params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "epochs=1000\n",
    "# hyperparameter variation\n",
    "lr=0.1\n",
    "neurons = [32,64,128,256]\n",
    "activations = ['sigmoid', 'relu', 'tanh']\n",
    "\n",
    "experiments = list(itertools.product(neurons, activations))\n",
    "\n",
    "for (hidden_neurons,hidden_activation) in experiments:\n",
    "    print('\\n############ Activation function: {} No. of neurons: {} ############'.format(hidden_activation, hidden_neurons))\n",
    "    model=NN(hidden_layers=5,hidden_neurons=hidden_neurons,hidden_activation=hidden_activation, lr=lr)\n",
    "    print('\\nTraining started!')\n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss,s1,a1,s2,a2 = model.forward(x_train)\n",
    "        if epoch%100==0:\n",
    "            print(\"Loss: {} Training progress: {}/{}\".format(loss,epoch,epochs))\n",
    "        model.backward(s1, a1, s2, a2)\n",
    "        \n",
    "    name = 'model_'+str(hidden_activation)+'_'+str(hidden_neurons)+'.pickle'\n",
    "    model.save_model(name=name)\n",
    "    stop = time.time()\n",
    "    \n",
    "    print('Training finished in {} s'.format(stop - start))\n",
    "    test_preds = model.predict(x_test)\n",
    "    print('Test Results-Accuracy: {} F1-Score: {}, Precision: {} Recall: {}'.format( np.mean(test_preds == y_test), f1_score(y_test, test_preds, average='micro'), precision_score(y_test, test_preds, average='micro'), recall_score(y_test, test_preds, average='micro') ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############(Val) Activation function: sigmoid No. of neurons: 32 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.294567298676679 Training progress: 0/1000\n",
      "Loss: 1.8908041806624656 Training progress: 100/1000\n",
      "Loss: 1.3929505670114768 Training progress: 200/1000\n",
      "Loss: 1.0629703667878727 Training progress: 300/1000\n",
      "Loss: 0.8634828861591332 Training progress: 400/1000\n",
      "Loss: 0.7310458618294778 Training progress: 500/1000\n",
      "Loss: 0.6371621684728309 Training progress: 600/1000\n",
      "Loss: 0.5679214331210309 Training progress: 700/1000\n",
      "Loss: 0.5154312849107762 Training progress: 800/1000\n",
      "Loss: 0.47472920490122816 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.2975906073733006 Training progress: 0/1000\n",
      "Loss: 1.8984211244502607 Training progress: 100/1000\n",
      "Loss: 1.4048436396163675 Training progress: 200/1000\n",
      "Loss: 1.0751591222637313 Training progress: 300/1000\n",
      "Loss: 0.873755529205051 Training progress: 400/1000\n",
      "Loss: 0.7397094723120292 Training progress: 500/1000\n",
      "Loss: 0.6451918341658059 Training progress: 600/1000\n",
      "Loss: 0.576157399820758 Training progress: 700/1000\n",
      "Loss: 0.524335484509604 Training progress: 800/1000\n",
      "Loss: 0.4844201875786178 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.2963204861817776 Training progress: 0/1000\n",
      "Loss: 1.9037190510614275 Training progress: 100/1000\n",
      "Loss: 1.408984344140048 Training progress: 200/1000\n",
      "Loss: 1.0743230947413926 Training progress: 300/1000\n",
      "Loss: 0.8726564754337195 Training progress: 400/1000\n",
      "Loss: 0.7395633552307702 Training progress: 500/1000\n",
      "Loss: 0.6454285621100524 Training progress: 600/1000\n",
      "Loss: 0.5760430113916273 Training progress: 700/1000\n",
      "Loss: 0.5234619220575201 Training progress: 800/1000\n",
      "Loss: 0.4827008886192384 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.2974862330560573 Training progress: 0/1000\n",
      "Loss: 1.8906052405815312 Training progress: 100/1000\n",
      "Loss: 1.391962649358864 Training progress: 200/1000\n",
      "Loss: 1.0637883969757242 Training progress: 300/1000\n",
      "Loss: 0.8644790277040634 Training progress: 400/1000\n",
      "Loss: 0.7318718616144149 Training progress: 500/1000\n",
      "Loss: 0.6381760204074888 Training progress: 600/1000\n",
      "Loss: 0.5695241584050736 Training progress: 700/1000\n",
      "Loss: 0.5178066656663525 Training progress: 800/1000\n",
      "Loss: 0.4778540875911821 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.302525404337499 Training progress: 0/1000\n",
      "Loss: 1.866812125912864 Training progress: 100/1000\n",
      "Loss: 1.3675944398696034 Training progress: 200/1000\n",
      "Loss: 1.0481102427925333 Training progress: 300/1000\n",
      "Loss: 0.8554649768841909 Training progress: 400/1000\n",
      "Loss: 0.72664894857218 Training progress: 500/1000\n",
      "Loss: 0.6341920991062912 Training progress: 600/1000\n",
      "Loss: 0.56539670385248 Training progress: 700/1000\n",
      "Loss: 0.5130350177993472 Training progress: 800/1000\n",
      "Loss: 0.4723477530072398 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.892875, 0.885875, 0.89, 0.8895, 0.891625]\n",
      "Train Results-Average validation accuracy: 0.8899750000000001\n",
      "\n",
      "############(Val) Activation function: relu No. of neurons: 32 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.266038882852192 Training progress: 0/1000\n",
      "Loss: 0.6163182473649474 Training progress: 100/1000\n",
      "Loss: 0.42035915469324486 Training progress: 200/1000\n",
      "Loss: 0.35149461167008594 Training progress: 300/1000\n",
      "Loss: 0.312326184711311 Training progress: 400/1000\n",
      "Loss: 0.2849606773280418 Training progress: 500/1000\n",
      "Loss: 0.2638986846714412 Training progress: 600/1000\n",
      "Loss: 0.24671400409608849 Training progress: 700/1000\n",
      "Loss: 0.2322125733854359 Training progress: 800/1000\n",
      "Loss: 0.21964710747808147 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.2714380855983074 Training progress: 0/1000\n",
      "Loss: 0.6305806089385724 Training progress: 100/1000\n",
      "Loss: 0.43234706071296614 Training progress: 200/1000\n",
      "Loss: 0.3635173792138557 Training progress: 300/1000\n",
      "Loss: 0.32429305002654885 Training progress: 400/1000\n",
      "Loss: 0.29677066608171865 Training progress: 500/1000\n",
      "Loss: 0.27548559924869037 Training progress: 600/1000\n",
      "Loss: 0.25785952374524096 Training progress: 700/1000\n",
      "Loss: 0.24275111413826497 Training progress: 800/1000\n",
      "Loss: 0.22951863200184283 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.2682604137275533 Training progress: 0/1000\n",
      "Loss: 0.6275363524373613 Training progress: 100/1000\n",
      "Loss: 0.4291491572198756 Training progress: 200/1000\n",
      "Loss: 0.35972070659021155 Training progress: 300/1000\n",
      "Loss: 0.3202316465424904 Training progress: 400/1000\n",
      "Loss: 0.2927175909993576 Training progress: 500/1000\n",
      "Loss: 0.27162436883159685 Training progress: 600/1000\n",
      "Loss: 0.2544750527574177 Training progress: 700/1000\n",
      "Loss: 0.2399646457329909 Training progress: 800/1000\n",
      "Loss: 0.22730143328544716 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.267672102694217 Training progress: 0/1000\n",
      "Loss: 0.6218809290123736 Training progress: 100/1000\n",
      "Loss: 0.4271840249882733 Training progress: 200/1000\n",
      "Loss: 0.3596972185581321 Training progress: 300/1000\n",
      "Loss: 0.32093844522898535 Training progress: 400/1000\n",
      "Loss: 0.29329130710287105 Training progress: 500/1000\n",
      "Loss: 0.27169316106023467 Training progress: 600/1000\n",
      "Loss: 0.2539979344408271 Training progress: 700/1000\n",
      "Loss: 0.2390595590471416 Training progress: 800/1000\n",
      "Loss: 0.22589242400801954 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.274366113202284 Training progress: 0/1000\n",
      "Loss: 0.6128768596093016 Training progress: 100/1000\n",
      "Loss: 0.4154771944591921 Training progress: 200/1000\n",
      "Loss: 0.34726288770880476 Training progress: 300/1000\n",
      "Loss: 0.30874701771335084 Training progress: 400/1000\n",
      "Loss: 0.2820479780719218 Training progress: 500/1000\n",
      "Loss: 0.26147728499535233 Training progress: 600/1000\n",
      "Loss: 0.24499818030821202 Training progress: 700/1000\n",
      "Loss: 0.23115409443644638 Training progress: 800/1000\n",
      "Loss: 0.21915059848832422 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.33325, 0.417375, 0.397125, 0.387625, 0.41975]\n",
      "Train Results-Average validation accuracy: 0.39102500000000007\n",
      "\n",
      "############(Val) Activation function: tanh No. of neurons: 32 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.2942995101941395 Training progress: 0/1000\n",
      "Loss: 0.796393013241282 Training progress: 100/1000\n",
      "Loss: 0.5115702666205532 Training progress: 200/1000\n",
      "Loss: 0.4055542740600565 Training progress: 300/1000\n",
      "Loss: 0.35006532746181485 Training progress: 400/1000\n",
      "Loss: 0.3145843707606133 Training progress: 500/1000\n",
      "Loss: 0.2889907649255473 Training progress: 600/1000\n",
      "Loss: 0.26904444980900644 Training progress: 700/1000\n",
      "Loss: 0.2526525594924042 Training progress: 800/1000\n",
      "Loss: 0.23866605843162256 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.2969750029794467 Training progress: 0/1000\n",
      "Loss: 0.8095487724743571 Training progress: 100/1000\n",
      "Loss: 0.5252513727313469 Training progress: 200/1000\n",
      "Loss: 0.4200198937682636 Training progress: 300/1000\n",
      "Loss: 0.3646102780834258 Training progress: 400/1000\n",
      "Loss: 0.3289610329966368 Training progress: 500/1000\n",
      "Loss: 0.3030767726874222 Training progress: 600/1000\n",
      "Loss: 0.28278021713952356 Training progress: 700/1000\n",
      "Loss: 0.26603215203055564 Training progress: 800/1000\n",
      "Loss: 0.2517122053559181 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.2996920757870503 Training progress: 0/1000\n",
      "Loss: 0.8072363666766921 Training progress: 100/1000\n",
      "Loss: 0.5214948960698906 Training progress: 200/1000\n",
      "Loss: 0.41524944208393644 Training progress: 300/1000\n",
      "Loss: 0.35955321259200057 Training progress: 400/1000\n",
      "Loss: 0.3240681199814247 Training progress: 500/1000\n",
      "Loss: 0.29857824433053387 Training progress: 600/1000\n",
      "Loss: 0.27873720052072337 Training progress: 700/1000\n",
      "Loss: 0.26240141561277475 Training progress: 800/1000\n",
      "Loss: 0.24841062002855982 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.2959409579505063 Training progress: 0/1000\n",
      "Loss: 0.8003684049472347 Training progress: 100/1000\n",
      "Loss: 0.5174259555385436 Training progress: 200/1000\n",
      "Loss: 0.4124995792020966 Training progress: 300/1000\n",
      "Loss: 0.3572137075157445 Training progress: 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3216578811908166 Training progress: 500/1000\n",
      "Loss: 0.29589494964169033 Training progress: 600/1000\n",
      "Loss: 0.2757640739434359 Training progress: 700/1000\n",
      "Loss: 0.25920980622079576 Training progress: 800/1000\n",
      "Loss: 0.24509724580655937 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.3021710232864403 Training progress: 0/1000\n",
      "Loss: 0.7930074524687151 Training progress: 100/1000\n",
      "Loss: 0.5114071834280369 Training progress: 200/1000\n",
      "Loss: 0.4046277075967032 Training progress: 300/1000\n",
      "Loss: 0.348413232327914 Training progress: 400/1000\n",
      "Loss: 0.31247361427017667 Training progress: 500/1000\n",
      "Loss: 0.2866201887690445 Training progress: 600/1000\n",
      "Loss: 0.2665567549115483 Training progress: 700/1000\n",
      "Loss: 0.25017712071679593 Training progress: 800/1000\n",
      "Loss: 0.2363193051580656 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.68, 0.694, 0.704125, 0.717375, 0.709625]\n",
      "Train Results-Average validation accuracy: 0.701025\n",
      "\n",
      "############(Val) Activation function: sigmoid No. of neurons: 64 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.3746580771347707 Training progress: 0/1000\n",
      "Loss: 1.725214993394985 Training progress: 100/1000\n",
      "Loss: 1.1459884645214997 Training progress: 200/1000\n",
      "Loss: 0.8431219547665719 Training progress: 300/1000\n",
      "Loss: 0.6837498009991202 Training progress: 400/1000\n",
      "Loss: 0.5872940054888721 Training progress: 500/1000\n",
      "Loss: 0.5223780609615326 Training progress: 600/1000\n",
      "Loss: 0.4755427134948342 Training progress: 700/1000\n",
      "Loss: 0.4401497368082531 Training progress: 800/1000\n",
      "Loss: 0.4124680433820192 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.3738032523235635 Training progress: 0/1000\n",
      "Loss: 1.7328187191197506 Training progress: 100/1000\n",
      "Loss: 1.1573254648505793 Training progress: 200/1000\n",
      "Loss: 0.853451498906896 Training progress: 300/1000\n",
      "Loss: 0.6934366318692301 Training progress: 400/1000\n",
      "Loss: 0.5970959946023467 Training progress: 500/1000\n",
      "Loss: 0.532611456634444 Training progress: 600/1000\n",
      "Loss: 0.486296952445222 Training progress: 700/1000\n",
      "Loss: 0.45142393513117374 Training progress: 800/1000\n",
      "Loss: 0.4242281466510141 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.3746272765926624 Training progress: 0/1000\n",
      "Loss: 1.7344494576374465 Training progress: 100/1000\n",
      "Loss: 1.1539318163224006 Training progress: 200/1000\n",
      "Loss: 0.8487006560182283 Training progress: 300/1000\n",
      "Loss: 0.6891887947493998 Training progress: 400/1000\n",
      "Loss: 0.5930760820113369 Training progress: 500/1000\n",
      "Loss: 0.5284390113660795 Training progress: 600/1000\n",
      "Loss: 0.4817435497931191 Training progress: 700/1000\n",
      "Loss: 0.446407488396133 Training progress: 800/1000\n",
      "Loss: 0.4187611135925704 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.372996540187739 Training progress: 0/1000\n",
      "Loss: 1.7230830113106963 Training progress: 100/1000\n",
      "Loss: 1.1445272037353091 Training progress: 200/1000\n",
      "Loss: 0.8439370011165354 Training progress: 300/1000\n",
      "Loss: 0.686128630885831 Training progress: 400/1000\n",
      "Loss: 0.5906943275713485 Training progress: 500/1000\n",
      "Loss: 0.5265180231986253 Training progress: 600/1000\n",
      "Loss: 0.48026180859777917 Training progress: 700/1000\n",
      "Loss: 0.44533062093421816 Training progress: 800/1000\n",
      "Loss: 0.41801527633285435 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.3683329013879915 Training progress: 0/1000\n",
      "Loss: 1.695633838103867 Training progress: 100/1000\n",
      "Loss: 1.1244450343816135 Training progress: 200/1000\n",
      "Loss: 0.8323757102781496 Training progress: 300/1000\n",
      "Loss: 0.6770733882265688 Training progress: 400/1000\n",
      "Loss: 0.5820781073406868 Training progress: 500/1000\n",
      "Loss: 0.5177018176677138 Training progress: 600/1000\n",
      "Loss: 0.47104396086799455 Training progress: 700/1000\n",
      "Loss: 0.4356724729833324 Training progress: 800/1000\n",
      "Loss: 0.4079561065576223 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.899875, 0.892625, 0.896125, 0.89575, 0.89925]\n",
      "Train Results-Average validation accuracy: 0.896725\n",
      "\n",
      "############(Val) Activation function: relu No. of neurons: 64 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.462775535232056 Training progress: 0/1000\n",
      "Loss: 0.5392123363179375 Training progress: 100/1000\n",
      "Loss: 0.3834289554726672 Training progress: 200/1000\n",
      "Loss: 0.32421505181229676 Training progress: 300/1000\n",
      "Loss: 0.2890817645362411 Training progress: 400/1000\n",
      "Loss: 0.2638621443235465 Training progress: 500/1000\n",
      "Loss: 0.24389593884320077 Training progress: 600/1000\n",
      "Loss: 0.22719824876397643 Training progress: 700/1000\n",
      "Loss: 0.21271403479952347 Training progress: 800/1000\n",
      "Loss: 0.19974725686459208 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.464689941157207 Training progress: 0/1000\n",
      "Loss: 0.5517356679269606 Training progress: 100/1000\n",
      "Loss: 0.39714964213350235 Training progress: 200/1000\n",
      "Loss: 0.3383745403962608 Training progress: 300/1000\n",
      "Loss: 0.3028165197486539 Training progress: 400/1000\n",
      "Loss: 0.2771866843309684 Training progress: 500/1000\n",
      "Loss: 0.25674912185436505 Training progress: 600/1000\n",
      "Loss: 0.23937096382884365 Training progress: 700/1000\n",
      "Loss: 0.22410426777113968 Training progress: 800/1000\n",
      "Loss: 0.21067372440357632 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.460346650655439 Training progress: 0/1000\n",
      "Loss: 0.5460034019637433 Training progress: 100/1000\n",
      "Loss: 0.39005028719533275 Training progress: 200/1000\n",
      "Loss: 0.33105918394426653 Training progress: 300/1000\n",
      "Loss: 0.295874206925518 Training progress: 400/1000\n",
      "Loss: 0.2706726175384152 Training progress: 500/1000\n",
      "Loss: 0.2505876736774841 Training progress: 600/1000\n",
      "Loss: 0.23358213108463907 Training progress: 700/1000\n",
      "Loss: 0.2186314973544535 Training progress: 800/1000\n",
      "Loss: 0.20535050093458546 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.4584614181660043 Training progress: 0/1000\n",
      "Loss: 0.5433059312977795 Training progress: 100/1000\n",
      "Loss: 0.3894279660675077 Training progress: 200/1000\n",
      "Loss: 0.3302955115890171 Training progress: 300/1000\n",
      "Loss: 0.2948738769138677 Training progress: 400/1000\n",
      "Loss: 0.26953088475264475 Training progress: 500/1000\n",
      "Loss: 0.24941468898517494 Training progress: 600/1000\n",
      "Loss: 0.23237615128015685 Training progress: 700/1000\n",
      "Loss: 0.21749253990021497 Training progress: 800/1000\n",
      "Loss: 0.20435528171893014 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.4639831998366453 Training progress: 0/1000\n",
      "Loss: 0.5319790807996199 Training progress: 100/1000\n",
      "Loss: 0.37862633014834707 Training progress: 200/1000\n",
      "Loss: 0.3200674521807681 Training progress: 300/1000\n",
      "Loss: 0.28525538936481937 Training progress: 400/1000\n",
      "Loss: 0.2601732623184379 Training progress: 500/1000\n",
      "Loss: 0.2404450036681326 Training progress: 600/1000\n",
      "Loss: 0.22394502774031536 Training progress: 700/1000\n",
      "Loss: 0.20959264398268576 Training progress: 800/1000\n",
      "Loss: 0.1968545068264842 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.614625, 0.64475, 0.6275, 0.630625, 0.633125]\n",
      "Train Results-Average validation accuracy: 0.630125\n",
      "\n",
      "############(Val) Activation function: tanh No. of neurons: 64 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.4841468269372986 Training progress: 0/1000\n",
      "Loss: 0.6358746149722058 Training progress: 100/1000\n",
      "Loss: 0.44130571197907104 Training progress: 200/1000\n",
      "Loss: 0.36517817594299434 Training progress: 300/1000\n",
      "Loss: 0.3215798118373517 Training progress: 400/1000\n",
      "Loss: 0.29144113632179286 Training progress: 500/1000\n",
      "Loss: 0.26829417687482865 Training progress: 600/1000\n",
      "Loss: 0.2493702675445581 Training progress: 700/1000\n",
      "Loss: 0.23327427567928163 Training progress: 800/1000\n",
      "Loss: 0.21921908609402002 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.4862241641004243 Training progress: 0/1000\n",
      "Loss: 0.646184074878039 Training progress: 100/1000\n",
      "Loss: 0.45234167343797854 Training progress: 200/1000\n",
      "Loss: 0.3776798958861662 Training progress: 300/1000\n",
      "Loss: 0.3351626257251461 Training progress: 400/1000\n",
      "Loss: 0.30570181297812005 Training progress: 500/1000\n",
      "Loss: 0.2829651345834308 Training progress: 600/1000\n",
      "Loss: 0.26429453548111465 Training progress: 700/1000\n",
      "Loss: 0.2483646768821933 Training progress: 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2344197520317913 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.4834795251995336 Training progress: 0/1000\n",
      "Loss: 0.640886323797289 Training progress: 100/1000\n",
      "Loss: 0.4467875051475563 Training progress: 200/1000\n",
      "Loss: 0.3707394009682183 Training progress: 300/1000\n",
      "Loss: 0.3274232267172905 Training progress: 400/1000\n",
      "Loss: 0.2976211066644753 Training progress: 500/1000\n",
      "Loss: 0.27480360314640234 Training progress: 600/1000\n",
      "Loss: 0.25618042602607866 Training progress: 700/1000\n",
      "Loss: 0.24034754139201187 Training progress: 800/1000\n",
      "Loss: 0.22651018680229942 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.485255194497843 Training progress: 0/1000\n",
      "Loss: 0.6402517953486158 Training progress: 100/1000\n",
      "Loss: 0.44722154838512235 Training progress: 200/1000\n",
      "Loss: 0.3718531517625554 Training progress: 300/1000\n",
      "Loss: 0.32877908988305576 Training progress: 400/1000\n",
      "Loss: 0.29906778273858636 Training progress: 500/1000\n",
      "Loss: 0.276280520115214 Training progress: 600/1000\n",
      "Loss: 0.2576578773606431 Training progress: 700/1000\n",
      "Loss: 0.24181519215825745 Training progress: 800/1000\n",
      "Loss: 0.22796913664849697 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.4920715946086593 Training progress: 0/1000\n",
      "Loss: 0.6296258302426344 Training progress: 100/1000\n",
      "Loss: 0.4371636068906537 Training progress: 200/1000\n",
      "Loss: 0.36159411997115226 Training progress: 300/1000\n",
      "Loss: 0.3184993948820331 Training progress: 400/1000\n",
      "Loss: 0.2888928992839356 Training progress: 500/1000\n",
      "Loss: 0.2662866673116875 Training progress: 600/1000\n",
      "Loss: 0.2478932060756191 Training progress: 700/1000\n",
      "Loss: 0.23231197122080152 Training progress: 800/1000\n",
      "Loss: 0.21875088055143108 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.72125, 0.693875, 0.731, 0.715375, 0.738]\n",
      "Train Results-Average validation accuracy: 0.7199\n",
      "\n",
      "############(Val) Activation function: sigmoid No. of neurons: 128 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.4505329324555074 Training progress: 0/1000\n",
      "Loss: 1.359736454953066 Training progress: 100/1000\n",
      "Loss: 0.8733049321457719 Training progress: 200/1000\n",
      "Loss: 0.6656573950297241 Training progress: 300/1000\n",
      "Loss: 0.5573974627549001 Training progress: 400/1000\n",
      "Loss: 0.4914483740953484 Training progress: 500/1000\n",
      "Loss: 0.44699511129959957 Training progress: 600/1000\n",
      "Loss: 0.41482899293613595 Training progress: 700/1000\n",
      "Loss: 0.3902908690261981 Training progress: 800/1000\n",
      "Loss: 0.37079350868852956 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.450830304092339 Training progress: 0/1000\n",
      "Loss: 1.3704002630006855 Training progress: 100/1000\n",
      "Loss: 0.8842045029996447 Training progress: 200/1000\n",
      "Loss: 0.676096696259144 Training progress: 300/1000\n",
      "Loss: 0.568078864562552 Training progress: 400/1000\n",
      "Loss: 0.5025304511030594 Training progress: 500/1000\n",
      "Loss: 0.4584627215028223 Training progress: 600/1000\n",
      "Loss: 0.42663927199634055 Training progress: 700/1000\n",
      "Loss: 0.40240416978865173 Training progress: 800/1000\n",
      "Loss: 0.3831764125814715 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.4561111589591724 Training progress: 0/1000\n",
      "Loss: 1.3701274093307332 Training progress: 100/1000\n",
      "Loss: 0.8814720957398179 Training progress: 200/1000\n",
      "Loss: 0.6731211176913239 Training progress: 300/1000\n",
      "Loss: 0.5644958756242395 Training progress: 400/1000\n",
      "Loss: 0.4982149466036488 Training progress: 500/1000\n",
      "Loss: 0.45353158629293255 Training progress: 600/1000\n",
      "Loss: 0.4212610475836121 Training progress: 700/1000\n",
      "Loss: 0.3967240836220287 Training progress: 800/1000\n",
      "Loss: 0.37730225574539394 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.455722920333523 Training progress: 0/1000\n",
      "Loss: 1.3598602703270095 Training progress: 100/1000\n",
      "Loss: 0.8746763453389527 Training progress: 200/1000\n",
      "Loss: 0.6676085185184709 Training progress: 300/1000\n",
      "Loss: 0.559886136265555 Training progress: 400/1000\n",
      "Loss: 0.49444416775111916 Training progress: 500/1000\n",
      "Loss: 0.4504307212524079 Training progress: 600/1000\n",
      "Loss: 0.4186397269006538 Training progress: 700/1000\n",
      "Loss: 0.39442446833244255 Training progress: 800/1000\n",
      "Loss: 0.3752090313361291 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.4425099525830594 Training progress: 0/1000\n",
      "Loss: 1.3387173813580595 Training progress: 100/1000\n",
      "Loss: 0.8634798073127409 Training progress: 200/1000\n",
      "Loss: 0.660666386212998 Training progress: 300/1000\n",
      "Loss: 0.5537060789116023 Training progress: 400/1000\n",
      "Loss: 0.48797705191373797 Training progress: 500/1000\n",
      "Loss: 0.44344600227515524 Training progress: 600/1000\n",
      "Loss: 0.4111457028016646 Training progress: 700/1000\n",
      "Loss: 0.3864887819392929 Training progress: 800/1000\n",
      "Loss: 0.3669059749113173 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.9055, 0.898875, 0.902375, 0.90225, 0.90575]\n",
      "Train Results-Average validation accuracy: 0.90295\n",
      "\n",
      "############(Val) Activation function: relu No. of neurons: 128 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.525124113347356 Training progress: 0/1000\n",
      "Loss: 0.4749875104818858 Training progress: 100/1000\n",
      "Loss: 0.3478536897825625 Training progress: 200/1000\n",
      "Loss: 0.29432408762569756 Training progress: 300/1000\n",
      "Loss: 0.2608059013915304 Training progress: 400/1000\n",
      "Loss: 0.23623338746569886 Training progress: 500/1000\n",
      "Loss: 0.21654927829311743 Training progress: 600/1000\n",
      "Loss: 0.19996898885822303 Training progress: 700/1000\n",
      "Loss: 0.1856229512651201 Training progress: 800/1000\n",
      "Loss: 0.17306654364973753 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.525719368107334 Training progress: 0/1000\n",
      "Loss: 0.4863762578755276 Training progress: 100/1000\n",
      "Loss: 0.36013783661347804 Training progress: 200/1000\n",
      "Loss: 0.3071103860936837 Training progress: 300/1000\n",
      "Loss: 0.2738234218087193 Training progress: 400/1000\n",
      "Loss: 0.24906326963570247 Training progress: 500/1000\n",
      "Loss: 0.22906014200398078 Training progress: 600/1000\n",
      "Loss: 0.2121038488572581 Training progress: 700/1000\n",
      "Loss: 0.1973605258891202 Training progress: 800/1000\n",
      "Loss: 0.18425917233429862 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.5273085426239734 Training progress: 0/1000\n",
      "Loss: 0.48013772853238296 Training progress: 100/1000\n",
      "Loss: 0.35277902761149 Training progress: 200/1000\n",
      "Loss: 0.3001744603214958 Training progress: 300/1000\n",
      "Loss: 0.2674132488174927 Training progress: 400/1000\n",
      "Loss: 0.2429971813130516 Training progress: 500/1000\n",
      "Loss: 0.2232799894706823 Training progress: 600/1000\n",
      "Loss: 0.20654484418432356 Training progress: 700/1000\n",
      "Loss: 0.19198750934488334 Training progress: 800/1000\n",
      "Loss: 0.17911309494350067 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.5357494323766696 Training progress: 0/1000\n",
      "Loss: 0.4782785253814551 Training progress: 100/1000\n",
      "Loss: 0.3531953948097772 Training progress: 200/1000\n",
      "Loss: 0.3004881100487248 Training progress: 300/1000\n",
      "Loss: 0.2677121633988747 Training progress: 400/1000\n",
      "Loss: 0.2434796490871493 Training progress: 500/1000\n",
      "Loss: 0.22381007002000922 Training progress: 600/1000\n",
      "Loss: 0.20711182036604028 Training progress: 700/1000\n",
      "Loss: 0.19254346764509858 Training progress: 800/1000\n",
      "Loss: 0.17948744702972297 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.524315308274692 Training progress: 0/1000\n",
      "Loss: 0.46931514527910323 Training progress: 100/1000\n",
      "Loss: 0.34376851254953145 Training progress: 200/1000\n",
      "Loss: 0.2912893044413224 Training progress: 300/1000\n",
      "Loss: 0.2586048347442981 Training progress: 400/1000\n",
      "Loss: 0.23442160218264657 Training progress: 500/1000\n",
      "Loss: 0.21504436339335092 Training progress: 600/1000\n",
      "Loss: 0.19873024894286126 Training progress: 700/1000\n",
      "Loss: 0.18457204968459795 Training progress: 800/1000\n",
      "Loss: 0.17207089536140624 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.595, 0.620875, 0.576625, 0.638125, 0.648]\n",
      "Train Results-Average validation accuracy: 0.6157250000000001\n",
      "\n",
      "############(Val) Activation function: tanh No. of neurons: 128 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.5393863794662646 Training progress: 0/1000\n",
      "Loss: 0.5078304450805948 Training progress: 100/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3769144855241541 Training progress: 200/1000\n",
      "Loss: 0.3212139026749872 Training progress: 300/1000\n",
      "Loss: 0.2869320075460371 Training progress: 400/1000\n",
      "Loss: 0.2621034295391862 Training progress: 500/1000\n",
      "Loss: 0.2424563517864665 Training progress: 600/1000\n",
      "Loss: 0.22605698999813062 Training progress: 700/1000\n",
      "Loss: 0.21189151576499346 Training progress: 800/1000\n",
      "Loss: 0.1993712894784462 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.538969597987775 Training progress: 0/1000\n",
      "Loss: 0.5185272644082882 Training progress: 100/1000\n",
      "Loss: 0.3885106572166627 Training progress: 200/1000\n",
      "Loss: 0.3336063356496906 Training progress: 300/1000\n",
      "Loss: 0.29979938939204726 Training progress: 400/1000\n",
      "Loss: 0.27518980416457894 Training progress: 500/1000\n",
      "Loss: 0.2555837656040152 Training progress: 600/1000\n",
      "Loss: 0.23910554117194124 Training progress: 700/1000\n",
      "Loss: 0.22478310970209572 Training progress: 800/1000\n",
      "Loss: 0.21205740874063211 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.5340776736678636 Training progress: 0/1000\n",
      "Loss: 0.5125026338971572 Training progress: 100/1000\n",
      "Loss: 0.3819181697434555 Training progress: 200/1000\n",
      "Loss: 0.3272427747740983 Training progress: 300/1000\n",
      "Loss: 0.2937807362711619 Training progress: 400/1000\n",
      "Loss: 0.269497652743395 Training progress: 500/1000\n",
      "Loss: 0.25016565244543143 Training progress: 600/1000\n",
      "Loss: 0.2339022653506475 Training progress: 700/1000\n",
      "Loss: 0.21973921285361162 Training progress: 800/1000\n",
      "Loss: 0.2071258753783091 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.5422877265683064 Training progress: 0/1000\n",
      "Loss: 0.5085536189185453 Training progress: 100/1000\n",
      "Loss: 0.3793928665539648 Training progress: 200/1000\n",
      "Loss: 0.325133588809916 Training progress: 300/1000\n",
      "Loss: 0.29187489850363296 Training progress: 400/1000\n",
      "Loss: 0.2677583916415216 Training progress: 500/1000\n",
      "Loss: 0.24859686646036142 Training progress: 600/1000\n",
      "Loss: 0.23251616991476945 Training progress: 700/1000\n",
      "Loss: 0.21854489543858763 Training progress: 800/1000\n",
      "Loss: 0.20612544383180112 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.5399504421615338 Training progress: 0/1000\n",
      "Loss: 0.5029642920833014 Training progress: 100/1000\n",
      "Loss: 0.37298972479361603 Training progress: 200/1000\n",
      "Loss: 0.317895320678296 Training progress: 300/1000\n",
      "Loss: 0.2842042415661923 Training progress: 400/1000\n",
      "Loss: 0.2599554525460479 Training progress: 500/1000\n",
      "Loss: 0.24085702521971125 Training progress: 600/1000\n",
      "Loss: 0.22496248271202954 Training progress: 700/1000\n",
      "Loss: 0.21125322932833712 Training progress: 800/1000\n",
      "Loss: 0.19913961757026435 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.647375, 0.69875, 0.6865, 0.653, 0.732]\n",
      "Train Results-Average validation accuracy: 0.683525\n",
      "\n",
      "############(Val) Activation function: sigmoid No. of neurons: 256 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.573485529778675 Training progress: 0/1000\n",
      "Loss: 1.0118339556879001 Training progress: 100/1000\n",
      "Loss: 0.672811982608621 Training progress: 200/1000\n",
      "Loss: 0.5415438302744686 Training progress: 300/1000\n",
      "Loss: 0.4718235384285739 Training progress: 400/1000\n",
      "Loss: 0.4279639857405242 Training progress: 500/1000\n",
      "Loss: 0.3973906359794375 Training progress: 600/1000\n",
      "Loss: 0.3745592490450083 Training progress: 700/1000\n",
      "Loss: 0.35664711009906414 Training progress: 800/1000\n",
      "Loss: 0.34206528478515846 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.5726036750497956 Training progress: 0/1000\n",
      "Loss: 1.0214534582981638 Training progress: 100/1000\n",
      "Loss: 0.6829226251739486 Training progress: 200/1000\n",
      "Loss: 0.5523352006791761 Training progress: 300/1000\n",
      "Loss: 0.4832031387108148 Training progress: 400/1000\n",
      "Loss: 0.4398115860778651 Training progress: 500/1000\n",
      "Loss: 0.4096105997145086 Training progress: 600/1000\n",
      "Loss: 0.3870805451965787 Training progress: 700/1000\n",
      "Loss: 0.3694164686588234 Training progress: 800/1000\n",
      "Loss: 0.3550416860944031 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.5683106059359946 Training progress: 0/1000\n",
      "Loss: 1.0209508805979475 Training progress: 100/1000\n",
      "Loss: 0.6811550136212069 Training progress: 200/1000\n",
      "Loss: 0.5499900970589029 Training progress: 300/1000\n",
      "Loss: 0.48024640176963906 Training progress: 400/1000\n",
      "Loss: 0.4363131390202745 Training progress: 500/1000\n",
      "Loss: 0.40567682856503917 Training progress: 600/1000\n",
      "Loss: 0.3828086340438896 Training progress: 700/1000\n",
      "Loss: 0.364883802365823 Training progress: 800/1000\n",
      "Loss: 0.35030702118690615 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.577083618857094 Training progress: 0/1000\n",
      "Loss: 1.009458559365058 Training progress: 100/1000\n",
      "Loss: 0.6734443313433307 Training progress: 200/1000\n",
      "Loss: 0.5441024745184827 Training progress: 300/1000\n",
      "Loss: 0.47546355579685207 Training progress: 400/1000\n",
      "Loss: 0.43226742924296946 Training progress: 500/1000\n",
      "Loss: 0.4021312240886399 Training progress: 600/1000\n",
      "Loss: 0.37960394488879723 Training progress: 700/1000\n",
      "Loss: 0.36191309659065074 Training progress: 800/1000\n",
      "Loss: 0.34749895212738163 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.611339265030582 Training progress: 0/1000\n",
      "Loss: 0.9963172276174206 Training progress: 100/1000\n",
      "Loss: 0.6652181237722053 Training progress: 200/1000\n",
      "Loss: 0.5359225829982497 Training progress: 300/1000\n",
      "Loss: 0.46669596527870794 Training progress: 400/1000\n",
      "Loss: 0.4229362735216948 Training progress: 500/1000\n",
      "Loss: 0.3923593940223193 Training progress: 600/1000\n",
      "Loss: 0.3695091515059578 Training progress: 700/1000\n",
      "Loss: 0.3515900096034354 Training progress: 800/1000\n",
      "Loss: 0.3370200862233446 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.9125, 0.908, 0.911, 0.91275, 0.91375]\n",
      "Train Results-Average validation accuracy: 0.9116\n",
      "\n",
      "############(Val) Activation function: relu No. of neurons: 256 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.714558024424232 Training progress: 0/1000\n",
      "Loss: 0.395737279642014 Training progress: 100/1000\n",
      "Loss: 0.3011205377581693 Training progress: 200/1000\n",
      "Loss: 0.2561239140550153 Training progress: 300/1000\n",
      "Loss: 0.2262162407825327 Training progress: 400/1000\n",
      "Loss: 0.20358374520280545 Training progress: 500/1000\n",
      "Loss: 0.18515963346940323 Training progress: 600/1000\n",
      "Loss: 0.16960781051442494 Training progress: 700/1000\n",
      "Loss: 0.15610111358429124 Training progress: 800/1000\n",
      "Loss: 0.14419018659709454 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.723379161952539 Training progress: 0/1000\n",
      "Loss: 0.4084714494545732 Training progress: 100/1000\n",
      "Loss: 0.31377610551409113 Training progress: 200/1000\n",
      "Loss: 0.268470956526815 Training progress: 300/1000\n",
      "Loss: 0.23815923827262594 Training progress: 400/1000\n",
      "Loss: 0.21511810511140608 Training progress: 500/1000\n",
      "Loss: 0.19632622020713703 Training progress: 600/1000\n",
      "Loss: 0.18028318779409483 Training progress: 700/1000\n",
      "Loss: 0.16625926847149794 Training progress: 800/1000\n",
      "Loss: 0.15387488885967662 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.709420927849013 Training progress: 0/1000\n",
      "Loss: 0.40600953524655625 Training progress: 100/1000\n",
      "Loss: 0.30989374917142737 Training progress: 200/1000\n",
      "Loss: 0.2643663831858464 Training progress: 300/1000\n",
      "Loss: 0.23433827540478833 Training progress: 400/1000\n",
      "Loss: 0.21153830457801392 Training progress: 500/1000\n",
      "Loss: 0.19303612540856915 Training progress: 600/1000\n",
      "Loss: 0.17736449443312763 Training progress: 700/1000\n",
      "Loss: 0.16375237077083976 Training progress: 800/1000\n",
      "Loss: 0.1516879642535371 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.725646047576274 Training progress: 0/1000\n",
      "Loss: 0.39980411114257314 Training progress: 100/1000\n",
      "Loss: 0.3048719856390562 Training progress: 200/1000\n",
      "Loss: 0.2593127935672404 Training progress: 300/1000\n",
      "Loss: 0.2290121510466998 Training progress: 400/1000\n",
      "Loss: 0.2059957460960432 Training progress: 500/1000\n",
      "Loss: 0.18724041440539327 Training progress: 600/1000\n",
      "Loss: 0.17132598474492436 Training progress: 700/1000\n",
      "Loss: 0.15752341366202882 Training progress: 800/1000\n",
      "Loss: 0.14532088055693249 Training progress: 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.737978771892125 Training progress: 0/1000\n",
      "Loss: 0.3920235979948848 Training progress: 100/1000\n",
      "Loss: 0.2971214751530084 Training progress: 200/1000\n",
      "Loss: 0.2521010780482147 Training progress: 300/1000\n",
      "Loss: 0.22235570928323398 Training progress: 400/1000\n",
      "Loss: 0.19996083629501385 Training progress: 500/1000\n",
      "Loss: 0.18178624004256252 Training progress: 600/1000\n",
      "Loss: 0.16641539378987555 Training progress: 700/1000\n",
      "Loss: 0.1531443344235417 Training progress: 800/1000\n",
      "Loss: 0.14151675788683055 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.309875, 0.31425, 0.33825, 0.3165, 0.328125]\n",
      "Train Results-Average validation accuracy: 0.3214\n",
      "\n",
      "############(Val) Activation function: tanh No. of neurons: 256 ############\n",
      "\n",
      "Training started (validation set 1/5)!\n",
      "Loss: 2.7970353423276095 Training progress: 0/1000\n",
      "Loss: 0.41833088160492427 Training progress: 100/1000\n",
      "Loss: 0.32744010372058413 Training progress: 200/1000\n",
      "Loss: 0.28440207639802184 Training progress: 300/1000\n",
      "Loss: 0.25601825906262266 Training progress: 400/1000\n",
      "Loss: 0.23450618582619737 Training progress: 500/1000\n",
      "Loss: 0.2169598460351342 Training progress: 600/1000\n",
      "Loss: 0.20200891976234897 Training progress: 700/1000\n",
      "Loss: 0.18890621547512865 Training progress: 800/1000\n",
      "Loss: 0.177202374426684 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 2/5)!\n",
      "Loss: 2.8078597455786123 Training progress: 0/1000\n",
      "Loss: 0.42942520704185144 Training progress: 100/1000\n",
      "Loss: 0.3393344692153422 Training progress: 200/1000\n",
      "Loss: 0.2963975188318907 Training progress: 300/1000\n",
      "Loss: 0.2678747247578551 Training progress: 400/1000\n",
      "Loss: 0.24612224442526964 Training progress: 500/1000\n",
      "Loss: 0.22828522963686604 Training progress: 600/1000\n",
      "Loss: 0.2130176176866548 Training progress: 700/1000\n",
      "Loss: 0.19958612265551864 Training progress: 800/1000\n",
      "Loss: 0.18754850357410235 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 3/5)!\n",
      "Loss: 2.797796939857232 Training progress: 0/1000\n",
      "Loss: 0.4253770344476312 Training progress: 100/1000\n",
      "Loss: 0.33424833066154835 Training progress: 200/1000\n",
      "Loss: 0.29105967988082 Training progress: 300/1000\n",
      "Loss: 0.26247219613975814 Training progress: 400/1000\n",
      "Loss: 0.24071402680970835 Training progress: 500/1000\n",
      "Loss: 0.2229083715455587 Training progress: 600/1000\n",
      "Loss: 0.20770632144202045 Training progress: 700/1000\n",
      "Loss: 0.19437327882438754 Training progress: 800/1000\n",
      "Loss: 0.18246559147764294 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 4/5)!\n",
      "Loss: 2.812801499620227 Training progress: 0/1000\n",
      "Loss: 0.42219540225474533 Training progress: 100/1000\n",
      "Loss: 0.3324894980249163 Training progress: 200/1000\n",
      "Loss: 0.28978468643725547 Training progress: 300/1000\n",
      "Loss: 0.26156264683566677 Training progress: 400/1000\n",
      "Loss: 0.24015320588170902 Training progress: 500/1000\n",
      "Loss: 0.22267550056105548 Training progress: 600/1000\n",
      "Loss: 0.2077676436454841 Training progress: 700/1000\n",
      "Loss: 0.19468729433632279 Training progress: 800/1000\n",
      "Loss: 0.1829882126795808 Training progress: 900/1000\n",
      "\n",
      "Training started (validation set 5/5)!\n",
      "Loss: 2.8081254211380235 Training progress: 0/1000\n",
      "Loss: 0.41412149274897603 Training progress: 100/1000\n",
      "Loss: 0.32332006087033266 Training progress: 200/1000\n",
      "Loss: 0.2804174207162171 Training progress: 300/1000\n",
      "Loss: 0.2522532291793547 Training progress: 400/1000\n",
      "Loss: 0.23101506780328487 Training progress: 500/1000\n",
      "Loss: 0.2137787531954019 Training progress: 600/1000\n",
      "Loss: 0.19916109618245606 Training progress: 700/1000\n",
      "Loss: 0.1864045640646666 Training progress: 800/1000\n",
      "Loss: 0.17505095704413015 Training progress: 900/1000\n",
      "5 fold validation accuracy [0.532625, 0.555875, 0.544875, 0.603, 0.48425]\n",
      "Train Results-Average validation accuracy: 0.544125\n"
     ]
    }
   ],
   "source": [
    "# copying the original data    \n",
    "y_train_or = np.copy(y_train)\n",
    "x_train_or = np.copy(x_train)\n",
    "y_test_or = np.copy(y_test)\n",
    "x_test_or = np.copy(x_test)\n",
    "\n",
    "# five fold cross validation\n",
    "folds=5\n",
    "val_acc=[]\n",
    "for (hidden_neurons,hidden_activation) in experiments:\n",
    "    print('\\n############(Val) Activation function: {} No. of neurons: {} ############'.format(hidden_activation, hidden_neurons))\n",
    "\n",
    "    for fold in range(0,folds):\n",
    "        # x_train.shape[0]=10000\n",
    "        start=int(fold*(x_train_or.shape[0]/folds))\n",
    "        stop=int((fold+1)*(x_train_or.shape[0]/folds))\n",
    "        \n",
    "        del x_train\n",
    "        del y_train\n",
    "        del x_test\n",
    "        del y_test\n",
    "\n",
    "        x_test=x_train_or[start:stop]\n",
    "        y_test=y_train_or[start:stop]\n",
    "        \n",
    "\n",
    "        x_train=np.vstack((x_train_or[:start],  x_train_or[stop:]))\n",
    "        y_train=np.append(y_train_or[:start],y_train_or[stop:])\n",
    "        # print(x_train.shape, y_train.shape)\n",
    "\n",
    "        model=NN(hidden_layers=5,hidden_neurons=hidden_neurons,hidden_activation=hidden_activation, lr=lr)\n",
    "        print('\\nTraining started (validation set {}/{})!'.format(fold+1,folds))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss,s1,a1,s2,a2 = model.forward(x_train)\n",
    "            if epoch%100==0:\n",
    "                print(\"Loss: {} Training progress: {}/{}\".format(loss,epoch,epochs))\n",
    "            model.backward(s1, a1, s2, a2)\n",
    "\n",
    "        train_preds= model.predict(x_train)\n",
    "        val_acc.append(np.mean(train_preds == y_train))\n",
    "    print(\"5 fold validation accuracy\",val_acc)\n",
    "    print('Train Results-Average validation accuracy: {}'.format(np.mean(np.array(val_acc)) ))\n",
    "    val_acc.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_sigmoid_32.pickle\n",
      "model_relu_32.pickle\n",
      "model_tanh_32.pickle\n",
      "model_sigmoid_64.pickle\n",
      "model_relu_64.pickle\n",
      "model_tanh_64.pickle\n",
      "model_sigmoid_128.pickle\n",
      "model_relu_128.pickle\n",
      "model_tanh_128.pickle\n",
      "model_sigmoid_256.pickle\n",
      "model_relu_256.pickle\n",
      "model_tanh_256.pickle\n"
     ]
    }
   ],
   "source": [
    "# Load model parameters\n",
    "for (hidden_neurons,hidden_activation) in experiments:\n",
    "    name = 'model_'+str(hidden_activation)+'_'+str(hidden_neurons)+'.pickle'\n",
    "    print(name)\n",
    "    with open(name, 'rb') as handle:\n",
    "        b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
